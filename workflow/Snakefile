import pandas as pd
from glob import glob
import numpy as np
from functools import lru_cache
import os 

configfile: "./config/config.yml"

output_dir = config["output_dir"]
# remove last slash if it exists
if output_dir[-1] == "/":
    output_dir = output_dir[:-1]

src_data_dir = config["src_data_dir"]
# remove last slash if it exists
if src_data_dir[-1] == "/":
    src_data_dir = src_data_dir[:-1]

# Get the mutation names
if 'mutation_labels' in config:
    mutation_names = config['mutation_labels']
else:
    mutation_names = {x : x for x in get_sim_muts()}

sample_sizes = [0]
if 'sample_sizes' in config:
    sample_sizes += config['sample_sizes']

xlim = {}
muts = {}

if 'fixation' in config:
    fixation = config['fixation']
    if 'xlim' in fixation:
        xlim['fixation'] = fixation['xlim']
    if 'muts' in fixation:
        muts['fixation'] = fixation['muts']


if 'sfs' in config:
    sfs = config['sfs']
    if 'xlim' in sfs:
        xlim['sfs'] = sfs['xlim']
    if 'muts' in sfs:
        muts['sfs'] = sfs['muts']

if 'fixationprobs' in config:
    fixationprobs = config['fixationprobs']
    if 'muts' in fixationprobs:
        muts['fixationprobs'] = fixationprobs['muts']

outcomes = ['fixation', 'sfs', 'ld', 'fixationprobs']
kld_outcomes = ['fixation', 'sfs']


# expensive I/O function, cache it, but not too much
@lru_cache(maxsize=10)
def get_sim_output_files(Q):
    samples, = glob_wildcards(f"{src_data_dir}/Q{Q}/sample_{{sample}}.vcf")
    # sort the samples for reproducibility
    samples = sorted(samples, key=lambda x: int(x))

    fixation_files = [f"{src_data_dir}/Q{Q}/fixation_{sample}.csv" for sample in samples]
    fixation_prob_files = [f"{src_data_dir}/Q{Q}/fixation_prob_{sample}.csv" for sample in samples]
    sample_files = [f"{src_data_dir}/Q{Q}/sample_{sample}.vcf" for sample in samples]

    return [fixation_files, fixation_prob_files, sample_files]

# Only need to cache once per simulation
@lru_cache(maxsize=1)
def get_qs():
    # Find all directories in the src_data_dir
    directories = os.listdir(src_data_dir)
    # Make sure the directories are of the form Q[q_value] with no letters after [q_value]
    directories = [dir for dir in directories if dir[0] == 'Q' and dir[1:].isdigit()]
    # The directories are names Q[q_value] so we need to extract the q_value
    qs = [int(dir[1:]) for dir in directories]
    # sort the qs for reproducibility
    qs = sorted(qs)
    return qs


def get_expected_output_batches():
    qs = get_qs()
    batches = [get_num_batches(Q) for Q in qs]


def get_batch_files(wildcards):
    Q = int(wildcards.Q)
    batch = int(wildcards.batch)
    sim_files = get_sim_output_files(Q)
    batch = int(wildcards.batch)
    batch_size = config['batch_size']
    start = batch * batch_size
    end = start + batch_size
    batch_files = list(np.concatenate([sim_files[i][start:end] for i in range(len(sim_files))]))
    return batch_files


def get_num_batches(Q):
    _, fixation_prob_files, _ = get_sim_output_files(Q=Q)
    num_batches = np.ceil(len(fixation_prob_files) / config['batch_size'])
    return int(num_batches)

@lru_cache(maxsize=1)
def get_sim_muts():
    _, fixation_prob_files, _ = get_sim_output_files(get_qs()[0])
    # Open up a random fixation_prob file and get the mutations
    fixation_prob_file = fixation_prob_files[0]
    df = pd.read_csv(fixation_prob_file)
    # the mutations are the column names
    mutations = df.columns.values.tolist()
    return mutations

@lru_cache(maxsize=1)
def get_fixation_binwidth():
    bin_widths = []
    lowest_q = get_qs()[0]
    fixation_files, _, _ = get_sim_output_files(lowest_q)
    # Open up a random fixation file and get the mutations
    fixation_file = fixation_files[0]
    df = pd.read_csv(fixation_file)
    muts = get_sim_muts()
    df = pd.read_csv(Path(fixation_file))
    for mut in muts:
        df_mut = df[df['mutation_id'] == mut]
        bin_width = 1
        for fixation_file in fixation_files:
            df = pd.read_csv(Path(fixation_file))
            df_mut = df[df['mutation_id'] == mut]
            if len(df_mut) > 0:
                fixation_times = ((df_mut['fix_gen'] - df_mut['origin_gen'])*lowest_q).to_numpy()
                bin_width = int(np.max(fixation_times) / 20)
                break
        bin_widths.append(bin_width)
    return bin_widths


onstart:
    shell("mkdir -p {output_dir}/graphs {output_dir}/summary_stats")

onsuccess:
    shell("rm -rf {output_dir}/batch_tmp_fulldata")

rule all:
    input:
        expand(f"{output_dir}/graphs/plot_{{outcome}}.svg", outcome=outcomes),
        expand(f"{output_dir}/summary_stats/plot_{{outcome}}.csv", outcome=outcomes),
        f"{output_dir}/graphs/rf_accuracy.svg",
        f"{output_dir}/summary_stats/rf_accuracy.csv",
        f"{output_dir}/graphs/lr_accuracy.svg",
        f"{output_dir}/summary_stats/lr_accuracy.csv",
        expand(f'{output_dir}/graphs/kl_divergence_{{outcome}}_{{sample}}.svg', outcome = kld_outcomes, sample=sample_sizes),
        expand(f'{output_dir}/summary_stats/kl_divergence_{{outcome}}_{{sample}}.csv', outcome = kld_outcomes, sample=sample_sizes),
        expand(f'{output_dir}/graphs/average_rmse_ld_{{sample}}.svg', sample=sample_sizes),
        expand(f'{output_dir}/summary_stats/average_rmse_ld_{{sample}}.csv', sample=sample_sizes),
        expand(f'{output_dir}/graphs/mean_percent_error_{{outcome}}_{{sample}}.svg', outcome=outcomes, sample=sample_sizes),
        expand(f'{output_dir}/summary_stats/mean_percent_error_{{outcome}}_{{sample}}.csv', outcome=outcomes, sample=sample_sizes)
        

rule graph_outcomes:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/plot_{{outcome}}.svg",
        f"{output_dir}/summary_stats/plot_{{outcome}}.csv"
    conda:
        config["conda_env"]
    group:
        "graphs"
    params:
        muts = muts.get('{outcome}', get_sim_muts()),
        mut_labels = lambda wildcards: [mutation_names[mut] for mut in muts.get(wildcards.outcome, get_sim_muts())],
        xlim = lambda wildcards: xlim.get(wildcards.outcome, 0)
    shell:
        ("""
        python scripts/create_summary_plots.py --input {input} --output {output_dir} --type {wildcards.outcome} --muts {params.muts} --mut_labels {params.mut_labels} --xlim {params.xlim}
        """)


rule graph_rf:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/rf_accuracy.svg",
        f"{output_dir}/summary_stats/rf_accuracy.csv"
    conda:
        config["conda_env"]
    group:
        "graphs"
    shell:
        ("""
        python scripts/create_ml_plots.py --input {input} --output {output_dir} --model rf 
        """)
    
rule graph_lr:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/lr_accuracy.svg",
        f"{output_dir}/summary_stats/lr_accuracy.csv"
    conda:
        config["conda_env"]
    group:
        "graphs"
    shell:
        ("""
        python scripts/create_ml_plots.py --input {input} --output {output_dir} --model lr 
        """)

rule kl_divergence:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/kl_divergence_{{outcome}}_{{sample}}.svg",
        f"{output_dir}/summary_stats/kl_divergence_{{outcome}}_{{sample}}.csv"
    conda: 
        config["conda_env"]
    params:
        muts = muts.get('{outcome}', get_sim_muts()),
        mut_labels = [mutation_names[mut] for mut in muts.get('{outcome}', get_sim_muts())]
    group:
        "stats"
    shell:
        ("""
        python scripts/create_divergence_plots.py --input {input} --output {output_dir} --type kl --muts {params.muts} --mut_labels {params.mut_labels} --stat {wildcards.outcome} --sample_size {wildcards.sample}
        """)

rule mean_percent_error:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/mean_percent_error_{{outcome}}_{{sample}}.svg",
        f"{output_dir}/summary_stats/mean_percent_error_{{outcome}}_{{sample}}.csv"
    conda:
        config["conda_env"]
    params:
        muts = muts.get('{outcome}', get_sim_muts()),
        mut_labels = [mutation_names[mut] for mut in muts.get('{outcome}', get_sim_muts())]
    group:
        "stats"
    shell:
        ("""
        python scripts/create_divergence_plots.py --input {input} --output {output_dir} --type mean_percent_error --muts {params.muts} --mut_labels {params.mut_labels} --stat {wildcards.outcome} --sample_size {wildcards.sample}
        """)

rule average_rmse_ld:
    input:
        f"{output_dir}/full_data.csv"
    output:
        f"{output_dir}/graphs/average_rmse_ld_{{sample}}.svg",
        f"{output_dir}/summary_stats/average_rmse_ld_{{sample}}.csv"
    conda:
        config["conda_env"]
    group:
        "stats"
    shell:
        ("""
        python scripts/create_divergence_plots.py --input {input} --output {output_dir} --type average_rmse --stat ld --sample_size {wildcards.sample}
        """)


rule create_fulldata:
    input: 
        [expand(f"{output_dir}/batch_tmp_fulldata/batch_{{Q}}_{{batch}}.csv", 
        Q=i, batch=range(get_num_batches(i))) for i in get_qs()]
    output:
        f"{output_dir}/full_data.csv"
    conda:
        config["conda_env"]
    shell:
        "python scripts/combine_fulldata_batches.py --input_files {input} --output_file {output}"
    
rule create_fulldata_batches:
    input:
        get_batch_files
    output:
        f"{output_dir}/batch_tmp_fulldata/batch_{{Q}}_{{batch}}.csv"
    conda:
        config["conda_env"]
    params:
        muts=get_sim_muts(),
        bin_widths=get_fixation_binwidth()
    shell:
        ("""
        mkdir -p {config[output_dir]}/batch_tmp_fulldata
        python scripts/create_fulldata_batches.py --muts {params.muts} --muts_fix_bin_width {params.bin_widths} --output_file {output} \
 --Q {wildcards.Q} --chr_len {config[chr_len]} --input_files {input}
        """)

rule clean_logs:
    shell:
        "rm -rf log/*"
